{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# License: BSD\n",
    "# Author: Sasank Chilamkurthy\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import torchvision.transforms as T\n",
    "import torchvision.datasets as dset\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader, sampler, Dataset\n",
    "from pytorch_load_data import load_data\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, recall_score\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import copy\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 64\n",
    "num_classes = 19\n",
    "\n",
    "dataloaders, poster_train, poster_val, poster_test = load_data(batchSize, -1)\n",
    "dataset_sizes = {}\n",
    "dataset_sizes['train'] = len(dataloaders['train'])\n",
    "dataset_sizes['val'] = len(dataloaders['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poster_train[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, num_epochs=25):\n",
    "    since = time.time()\n",
    "    n_classes= 19\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_prec = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            running_precision = []\n",
    "            running_recall = []\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                \n",
    "                labels_tensor = torch.zeros((batchSize, num_classes))\n",
    "                for idx,each in enumerate(labels):\n",
    "                    labels_tensor[:,idx] = each\n",
    "\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels_tensor.to(device)\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                # forward -- track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    scores = model(inputs)\n",
    "                    loss = multilabel_Loss(scores, labels)                        \n",
    "                    print('Loss: %s' %(loss))\n",
    "                    train_losses.append(loss)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Statistics --multilabel precision\n",
    "                average_precision = average_precision_score(labels, scores.data, average=\"micro\")\n",
    "                print(\"Average precision: %s\" %(average_precision))\n",
    "                running_loss += loss.item() #* inputs.size(0)\n",
    "                running_precision.append(average_precision)\n",
    "#                 running_recall.append(np.mean(list_r))                \n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_prec = np.mean(running_precision)\n",
    "#             epoch_recall = np.mean(running_recall)            \n",
    "            \n",
    "            if phase == 'val':\n",
    "                epoch_val_precison.append(epoch_prec)\n",
    "            else:\n",
    "                epoch_train_precision.append(epoch_prec)\n",
    "\n",
    "            print('END OF EPOCH')\n",
    "            print('{} Loss: {:.4f} Prec: {:.4f}'.format(phase, epoch_loss, epoch_prec))\n",
    "\n",
    "#             # deep copy the model\n",
    "            if phase == 'val' and epoch_prec > best_prec:\n",
    "                  best_prec = epoch_prec\n",
    "                  best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Prec: {:4f}'.format(best_prec))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilabel_Loss(x, y):\n",
    "    \n",
    "    ## to calculate the log of the \n",
    "    shifted_logits = x - torch.max(x, dim=1, keepdim=True)[0]\n",
    "    summed = torch.sum(torch.exp(shifted_logits), dim=1, keepdim=True)    \n",
    "    log_probs = torch.log(torch.exp(shifted_logits) / summed)\n",
    "    N, _ = x.size()\n",
    "    \n",
    "    p_loss = -1 * torch.sum(y * log_probs) / N    \n",
    "    \n",
    "\n",
    "    return p_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "# for param in model_conv.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "model_conv = model_conv.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n",
      "Loss: tensor(7.9209)\n",
      "Average precision: 0.13824352891203812\n",
      "Loss: tensor(7.9666)\n",
      "Average precision: 0.14361613402118767\n",
      "Loss: tensor(7.3015)\n",
      "Average precision: 0.14447359323056772\n",
      "Loss: tensor(7.5809)\n",
      "Average precision: 0.13147043418386573\n",
      "Loss: tensor(7.0943)\n",
      "Average precision: 0.1152821589393349\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b7796e91eca9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlearn_rt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlearning_rates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0moptimizer_conv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_conv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearn_rt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mmodel_conv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_conv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_conv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-5265034718fd>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0;31m# forward -- track history if only in train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultilabel_Loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss: %s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 301\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "epoch_train_precision = []\n",
    "epoch_val_precison = []\n",
    "\n",
    "learning_rates = [1e-6, 1e-4, 1e-2, 1e-1]\n",
    "\n",
    "for learn_rt in learning_rates:\n",
    "    optimizer_conv = optim.Adam(model_conv.parameters(), lr=learn_rt)\n",
    "    model_conv = train_model(model_conv, optimizer_conv, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'Iteration')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6db64a59b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(311)\n",
    "plt.title('Training loss')\n",
    "plt.plot(train_losses, 'o')\n",
    "plt.xlabel('Iteration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
