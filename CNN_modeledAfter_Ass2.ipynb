{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, sampler, Dataset \n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import glob\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MOVIES(Dataset):\n",
    "\n",
    "# A customized data loader for MNIST.\\n\",\n",
    "    def __init__(self, root,transform=None,preload=False, train=True):\n",
    "#             Intialize the MNIST dataset,\n",
    "#             Args:,\n",
    "#                 - root: root directory of the dataset\n",
    "#                 - transform: a custom tranform function\n",
    "#                 - preload: if preload the dataset into memory\n",
    "        self.images = None\n",
    "        self.labels = None\n",
    "        self.filenames = []\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "            \n",
    "        for i in range(10):\n",
    "            filenames = glob.glob(osp.join(root, str(i), '*.jpg'))\n",
    "            for fn in filenames:\n",
    "                self.filenames.append((fn, i)) # (filename, label)\n",
    "\n",
    "        # if preload dataset into memory\",\n",
    "        if preload:\n",
    "            self._preload()\n",
    "\n",
    "        self.len = len(self.filenames)\n",
    "\n",
    "    def _preload(self):\n",
    "\n",
    "#        Preload dataset to memory\n",
    "\n",
    "        self.labels = []\n",
    "        self.images = []\n",
    "        for image_fn, label in self.filenames:            \n",
    "            # load images\n",
    "            image = Image.open(image_fn)\n",
    "            # avoid too many opened files bug\n",
    "            self.images.append(image.copy())\n",
    "            image.close()\n",
    "            self.labels.append(label)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "#              Get a sample from the dataset\n",
    "\n",
    "        if self.images is not None:\n",
    "            # If dataset is preloaded\n",
    "            image = self.images[index]\n",
    "            label = self.labels[index]\n",
    "        else:\n",
    "            # If on-demand data loading\n",
    "            image_fn, label = self.filenames[index]\n",
    "            image = Image.open(image_fn)\n",
    "\n",
    "        # May use transform function to transform samples\n",
    "        # e.g., random crop, whitening\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        # return image and label\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "#             Total number of samples in the dataset\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataSetFolder = 'datasets/split_drama_posters/train/'\n",
    "DataSetFolder_test = 'datasets/split_drama_posters/test/'\n",
    "\n",
    "NUM_TRAIN = 4000\n",
    "NUM_TOTALIMAGES = 4291\n",
    "\n",
    "BATCHSIZE = 32 #cifar10 set to 64\n",
    "R_Mean = .4914\n",
    "G_Mean = .4822\n",
    "B_Mean = .4465\n",
    "R_Std = .2023\n",
    "G_Std = .1994\n",
    "B_Std = .2010\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This cell is drafted after Assignment2 Pytorch - but those images were already square!!!!\n",
    "\n",
    "## to normalize by subtracting the mean RGB vlaue and dividing by the standard deviations of each RGB value\n",
    "## the Mean and STD are from CIFAR10 dataset\n",
    "data_transforms = T.Compose([\n",
    "                T.Resize((32,32)),\n",
    "                T.ToTensor()])\n",
    "#                 T.Normalize((R_Mean, G_Mean, B_Mean), (R_Std, G_Std, B_Std))])\n",
    "\n",
    "poster_train = MOVIES(DataSetFolder, preload=False, transform=data_transforms, train=True)\n",
    "loader_train = DataLoader(poster_train, batch_size=BATCHSIZE, sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "poster_val = MOVIES(DataSetFolder, preload=False, transform=data_transforms, train=True)\n",
    "loader_val = DataLoader(poster_val, batch_size=BATCHSIZE, sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, NUM_TOTALIMAGES)))\n",
    "\n",
    "poster_test = MOVIES(DataSetFolder_test, preload=False, transform=data_transforms, train=False)\n",
    "loader_test = DataLoader(poster_test, batch_size=BATCHSIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4294"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(poster_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poster_train[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0) tensor(0) tensor(1) tensor(0) tensor(0) tensor(1) tensor(0) tensor(1) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(1) tensor(0) tensor(0) tensor(1) tensor(1) tensor(0) tensor(0) tensor(0) tensor(1) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(loader_train)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % labels[j] for j in range(BATCHSIZE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "dtype = torch.float32 \n",
    "\n",
    "if USE_GPU and torch.cuda.is_available(): \n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before flattening:  tensor([[[[  0.,   1.],\n",
      "          [  2.,   3.],\n",
      "          [  4.,   5.]]],\n",
      "\n",
      "\n",
      "        [[[  6.,   7.],\n",
      "          [  8.,   9.],\n",
      "          [ 10.,  11.]]]])\n",
      "After flattening:  tensor([[  0.,   1.,   2.,   3.,   4.,   5.],\n",
      "        [  6.,   7.,   8.,   9.,  10.,  11.]])\n"
     ]
    }
   ],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] #read in N, C, H, W\n",
    "    return x.view(N, -1) # \"flatten\" the C * H * W values into a sing le vector per image\n",
    "\n",
    "def test_flatten():\n",
    "    x = torch.arange(12).view(2, 1, 3, 2) \n",
    "    print('Before flattening: ', x) \n",
    "    print('After flattening: ', flatten(x))\n",
    "\n",
    "test_flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x): \n",
    "        return flatten(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model): \n",
    "    if loader.dataset.train:\n",
    "        print('Checking accuracy on validation set') \n",
    "    else:\n",
    "        print('Checking accuracy on test set')\n",
    "\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval() # set model to evaluation mode \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype) # move to device, e.\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples , 100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_loss = []\n",
    "\n",
    "def train_part(model, optimizer, epochs=1): \n",
    "    \"\"\"\n",
    "     - model: A PyTorch Module giving the model to train.\n",
    "     - optimizer: An Optimizer object we will use to train the model\n",
    "     - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device) # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train() # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype) # move to device, e.\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            \n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "            main_loss.append(loss)\n",
    "            \n",
    "            # Zero out all of the gradients for the variables which th\n",
    "            # will update.\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "            \n",
    "            # Actually update the parameters of the model using the gr\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                print('Epoch: %s' % (e))\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item())) \n",
    "                check_accuracy(loader_val, model)\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Iteration 0, loss = 0.6919\n",
      "Checking accuracy on validation set\n",
      "Got 0 / 291 correct (0.00)\n",
      "\n",
      "Epoch: 0\n",
      "Iteration 100, loss = 0.7176\n",
      "Checking accuracy on validation set\n",
      "Got 0 / 291 correct (0.00)\n",
      "\n",
      "Epoch: 1\n",
      "Iteration 0, loss = 0.6987\n",
      "Checking accuracy on validation set\n",
      "Got 0 / 291 correct (0.00)\n",
      "\n",
      "Epoch: 1\n",
      "Iteration 100, loss = 0.6994\n",
      "Checking accuracy on validation set\n",
      "Got 4 / 291 correct (1.37)\n",
      "\n",
      "Epoch: 2\n",
      "Iteration 0, loss = 0.6747\n",
      "Checking accuracy on validation set\n",
      "Got 116 / 291 correct (39.86)\n",
      "\n",
      "Epoch: 2\n",
      "Iteration 100, loss = 0.7600\n",
      "Checking accuracy on validation set\n",
      "Got 6 / 291 correct (2.06)\n",
      "\n",
      "Epoch: 3\n",
      "Iteration 0, loss = 0.6691\n",
      "Checking accuracy on validation set\n",
      "Got 2 / 291 correct (0.69)\n",
      "\n",
      "Epoch: 3\n",
      "Iteration 100, loss = 0.6790\n",
      "Checking accuracy on validation set\n",
      "Got 126 / 291 correct (43.30)\n",
      "\n",
      "Epoch: 4\n",
      "Iteration 0, loss = 0.6427\n",
      "Checking accuracy on validation set\n",
      "Got 52 / 291 correct (17.87)\n",
      "\n",
      "Epoch: 4\n",
      "Iteration 100, loss = 0.6195\n",
      "Checking accuracy on validation set\n",
      "Got 19 / 291 correct (6.53)\n",
      "\n",
      "Epoch: 5\n",
      "Iteration 0, loss = 0.6181\n",
      "Checking accuracy on validation set\n",
      "Got 80 / 291 correct (27.49)\n",
      "\n",
      "Epoch: 5\n",
      "Iteration 100, loss = 0.5764\n",
      "Checking accuracy on validation set\n",
      "Got 221 / 291 correct (75.95)\n",
      "\n",
      "Epoch: 6\n",
      "Iteration 0, loss = 0.6459\n",
      "Checking accuracy on validation set\n",
      "Got 177 / 291 correct (60.82)\n",
      "\n",
      "Epoch: 6\n",
      "Iteration 100, loss = 0.8361\n",
      "Checking accuracy on validation set\n",
      "Got 52 / 291 correct (17.87)\n",
      "\n",
      "Epoch: 7\n",
      "Iteration 0, loss = 0.6699\n",
      "Checking accuracy on validation set\n",
      "Got 106 / 291 correct (36.43)\n",
      "\n",
      "Epoch: 7\n",
      "Iteration 100, loss = 0.6484\n",
      "Checking accuracy on validation set\n",
      "Got 86 / 291 correct (29.55)\n",
      "\n",
      "Epoch: 8\n",
      "Iteration 0, loss = 0.6406\n",
      "Checking accuracy on validation set\n",
      "Got 80 / 291 correct (27.49)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "channel_1 = 32\n",
    "channel_2 = 16\n",
    "channel_3 = 32\n",
    "channel_4 = 16\n",
    "learning_rate = .01\n",
    "in_channel = 3\n",
    "num_classes = 2\n",
    "num_features = 3*32*32\n",
    "\n",
    "model = nn.Sequential(\n",
    "#Layer 1\n",
    "    nn.Conv2d(in_channel, channel_1, 5, padding=2),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(3, stride=1, padding=1),\n",
    "    nn.BatchNorm2d(channel_1),\n",
    "#Layer2\n",
    "    nn.Conv2d(channel_1, channel_2, 3, padding=1),\n",
    "    nn.ReLU(),\n",
    "#     nn.BatchNorm2d(channel_2),\n",
    "    #Layer2.2 ====> added in as an experiment\n",
    "    nn.Conv2d(channel_2, channel_3, 3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(3, stride=1, padding=1),\n",
    "#     nn.BatchNorm2d(channel_3),\n",
    "#Layer3\n",
    "    nn.Conv2d(channel_3, channel_4, 3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(3, stride=1, padding=1),\n",
    "#     nn.BatchNorm2d(channel_4),\n",
    "#Layer4\n",
    "    Flatten(),\n",
    "    nn.Linear((channel_4*32*32), num_classes)\n",
    ")\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, nesterov=True)\n",
    "\n",
    "train_part(model, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "plt.title('Training loss')\n",
    "plt.plot(main_loss, 'o')\n",
    "plt.xlabel('Iteration')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
