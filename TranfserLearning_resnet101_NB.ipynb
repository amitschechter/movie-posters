{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# License: BSD\n",
    "# Author: Sasank Chilamkurthy\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from torch.utils.data import DataLoader \n",
    "from torch.utils.data import sampler\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import glob\n",
    "import os.path as osp\n",
    "from PIL import Image\n",
    "import pickle\n",
    "\n",
    "from pytorch_load_data import load_data\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize=64\n",
    "dataloaders, poster_train, poster_val, poster_test = load_data(batchsize=batchsize)\n",
    "dataset_sizes = {}\n",
    "dataset_sizes['train'] = len(dataloaders['train'])\n",
    "dataset_sizes['val'] = len(dataloaders['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# # functions to show an image\n",
    "# def imshow(img):\n",
    "#     npimg = img.numpy()\n",
    "#     plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "# # get some random training images\n",
    "# dataiter = iter(dataloaders['train'])\n",
    "# images, labels = dataiter.next()\n",
    "\n",
    "\n",
    "# # show images\n",
    "# imshow(torchvision.utils.make_grid(images))\n",
    "# # print labels\n",
    "# # print(' '.join('%5s' % labels[j] for j in range(BATCHSIZE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_positives_count = 1601.0\n",
    "train_negatives_count = 1744.0\n",
    "val_positives_count = 461.0\n",
    "val_negatives_count = 493.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    train_losses, val_losses, train_accuracies, val_accuracies = [], [], [], []\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "#                 scheduler.step()    # Update learning rate (decay)\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            running_corrects_positives = 0\n",
    "            running_pred_positives = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        train_losses.append(loss)\n",
    "                    elif phase == 'val':\n",
    "                        val_losses.append(loss)\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                print(torch.ones(batchsize, dtype=torch.float64, device=device) == preds.data.double())\n",
    "                running_corrects_positives += torch.sum(preds.data == labels.data and preds.data == torch.ones(batchsize, dtype=torch.float64, device=device))\n",
    "                running_pred_positives += torch.sum(preds.data.double() == torch.ones(batchsize, dtype=torch.float64, device=device))\n",
    "                \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            epoch_precision, epoch_recall = 0, 0\n",
    "            if phase == 'train':\n",
    "                epoch_precision = running_corrects_positives.double() / running_pred_positives.double()\n",
    "                epoch_recall = running_corrects_positives.double() / train_positives_count\n",
    "                train_accuracies.append(epoch_acc)\n",
    "            elif phase == 'val':\n",
    "                epoch_precision = running_corrects_positives.double() / running_pred_positives.double()\n",
    "                epoch_recall = running_corrects_positives.double() / val_positives_count\n",
    "                val_accuracies.append(epoch_acc)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            print('Precision: {:.4f}, Recall: {:.4f}'.format(\n",
    "                epoch_precision, epoch_recall))\n",
    "            time_elapsed = time.time() - since\n",
    "            print('Time passes: {:.0f}m {:.0f}s'.format(\n",
    "                time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, train_losses, val_losses, train_accuracies, val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "# for param in model_conv.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_conv = model_conv.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that only parameters of final layer are being optimized as\n",
    "# opoosed to before.\n",
    "optimizer_conv = optim.Adam(model_conv.parameters(), lr=0.01)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 5e-05\n",
      "Epoch 0/0\n",
      "----------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e2c423b7407c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0moptimizer_conv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_conv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     model_conv, train_losses, val_losses, train_accuracies, val_accuracies = train_model(model_conv, criterion, optimizer_conv,\n\u001b[0;32m---> 20\u001b[0;31m                              exp_lr_scheduler, num_epochs=1)\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"learning_rate: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-a871e03feacf>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0;31m# zero the parameter gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "learning_rates = [5e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1]\n",
    "for learning_rate in learning_rates:\n",
    "    print(\"learning_rate: {}\".format(learning_rate))\n",
    "    model_conv = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "    for param in model_conv.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Parameters of newly constructed modules have requires_grad=True by default\n",
    "    num_ftrs = model_conv.fc.in_features\n",
    "    model_conv.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "    model_conv = model_conv.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    exp_lr_scheduler = None\n",
    "    optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    model_conv, train_losses, val_losses, train_accuracies, val_accuracies = train_model(model_conv, criterion, optimizer_conv,\n",
    "                             exp_lr_scheduler, num_epochs=1)\n",
    "    \n",
    "    print(\"learning_rate: {}\".format(learning_rate))\n",
    "    \n",
    "    plt.subplot(311)\n",
    "    plt.title('Training loss')\n",
    "    plt.plot(train_losses, 'o')\n",
    "    plt.xlabel('Iteration')\n",
    "\n",
    "    plt.subplot(312)\n",
    "    plt.title('Validation loss')\n",
    "    plt.plot(val_losses, 'o')\n",
    "    plt.xlabel('Iteration')\n",
    "    \n",
    "    plt.subplot(313)\n",
    "    plt.title('Accuracy')\n",
    "    plt.plot(train_accuracies, '-o', label='Train Accuracy')\n",
    "    plt.plot(val_accuracies, '-o', label='Val Accuracy')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.legend(loc='lower center')\n",
    "    \n",
    "    plt.savefig('Transfer learning'+str(learning_rate)+'.pdf')\n",
    "    \n",
    "    with open(str(learning_rate)+'.pickle', 'wb') as file:\n",
    "        pickle.dump((train_losses, val_losses, train_accuracy, val_accuracy), file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.subplot(311)\n",
    "# plt.title('Training loss')\n",
    "# plt.plot(train_losses, 'o')\n",
    "# plt.xlabel('Iteration')\n",
    "\n",
    "# plt.subplot(312)\n",
    "# plt.title('Validation loss')\n",
    "# plt.plot(val_losses, 'o')\n",
    "# plt.xlabel('Iteration')\n",
    "\n",
    "# plt.subplot(313)\n",
    "# plt.title('Accuracy')\n",
    "# plt.plot(train_accuracies, '-o', label='Train Accuracy')\n",
    "# plt.plot(val_accuracies, '-o', label='Val Accuracy')\n",
    "# plt.xlabel('Iteration')\n",
    "# plt.legend(loc='lower center')\n",
    "\n",
    "# plt.savefig('Transfer learning'+str(learning_rate)+'.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(2):\n",
    "#     plt.subplot(311)\n",
    "#     plt.title('Training loss')\n",
    "#     plt.plot(train_losses, 'o')\n",
    "#     plt.xlabel('Iteration')\n",
    "\n",
    "#     plt.subplot(312)\n",
    "#     plt.title('Validation loss')\n",
    "#     plt.plot(val_losses, 'o')\n",
    "#     plt.xlabel('Iteration')\n",
    "    \n",
    "#     plt.subplot(313)\n",
    "#     plt.title('Amit loss')\n",
    "#     plt.plot(val_losses, 'o')\n",
    "#     plt.xlabel('Iteration')\n",
    "    \n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = 1e-3\n",
    "# with open(str(lr)+'.pickle', 'rb') as handle:\n",
    "#     train_losses, val_losses = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_model(model_conv)\n",
    "\n",
    "# plt.ioff()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.subplot(1, 1, 1)\n",
    "# plt.title('Training loss')\n",
    "# plt.plot(train_losses, 'o')\n",
    "# plt.xlabel('Iteration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.subplot(1, 1, 1)\n",
    "# plt.title('Validation loss')\n",
    "# plt.plot(val_losses, 'o')\n",
    "# plt.xlabel('Iteration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
