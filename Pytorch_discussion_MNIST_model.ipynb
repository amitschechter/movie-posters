{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "import glob\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MOVIES(Dataset):\n",
    "\n",
    "# A customized data loader for MNIST.\\n\",\n",
    "    def __init__(self, root,transform=None,preload=False):\n",
    "#             Intialize the MNIST dataset,\n",
    "#             Args:,\n",
    "#                 - root: root directory of the dataset\n",
    "#                 - transform: a custom tranform function\n",
    "#                 - preload: if preload the dataset into memory\n",
    "        self.images = None\n",
    "        self.labels = None\n",
    "        self.filenames = []\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "            \n",
    "        for i in range(10):\n",
    "            filenames = glob.glob(osp.join(root, str(i), '*.jpg'))\n",
    "            for fn in filenames:\n",
    "                self.filenames.append((fn, i)) # (filename, label)\n",
    "\n",
    "        # if preload dataset into memory\",\n",
    "        if preload:\n",
    "            self._preload()\n",
    "\n",
    "        self.len = len(self.filenames)\n",
    "\n",
    "    def _preload(self):\n",
    "\n",
    "#        Preload dataset to memory\n",
    "\n",
    "        self.labels = []\n",
    "        self.images = []\n",
    "        for image_fn, label in self.filenames:            \n",
    "            # load images\n",
    "            image = Image.open(image_fn)\n",
    "            # avoid too many opened files bug\n",
    "            self.images.append(image.copy())\n",
    "            image.close()\n",
    "            self.labels.append(label)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "#              Get a sample from the dataset\n",
    "\n",
    "        if self.images is not None:\n",
    "            # If dataset is preloaded\n",
    "            image = self.images[index]\n",
    "            label = self.labels[index]\n",
    "        else:\n",
    "            # If on-demand data loading\n",
    "            image_fn, label = self.filenames[index]\n",
    "            image = Image.open(image_fn)\n",
    "\n",
    "        # May use transform function to transform samples\n",
    "        # e.g., random crop, whitening\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        # return image and label\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "#             Total number of samples in the dataset\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "        transforms.Resize((28,28)),\n",
    "#         transforms.RandomResizedCrop(28),\n",
    "#         transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "#         transforms.Normalize([R_Mean, G_Mean, B_Mean], [R_std, G_Std, B_Std])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = MOVIES(root='datasets/split_drama_posters/train/', preload=False, transform=data_transforms)\n",
    "# Use the torch dataloader to iterate through the dataset\n",
    "# trainset_loader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=1)\n",
    "trainset_loader = DataLoader(trainset, shuffle=True, num_workers=1)\n",
    "\n",
    "# load the testset\n",
    "testset = MOVIES(\n",
    "    root='datasets/split_drama_posters/test/',\n",
    "    preload=False, transform=transforms.ToTensor(),\n",
    ")\n",
    "# # Use the torch dataloader to iterate through the dataset\n",
    "testset_loader = DataLoader(testset, batch_size=1000, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4294\n"
     ]
    }
   ],
   "source": [
    "print(len(trainset))\n",
    "# print(len(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f34d6ef2cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainset_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % labels[j] for j in range(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available, otherwise stick with cpu\n",
    "use_cuda = torch.cuda.is_available()\n",
    "torch.manual_seed(123)\n",
    "device = torch.device(cuda if use_cuda else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,each in enumerate(trainset):\n",
    "#     if i%100==0:\n",
    "#         print(i)\n",
    "#     if each[0].shape[0] != 3 or each[0].shape[1] != 28 or each[0].shape[2] != 28:\n",
    "#         print(i,each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #elephantman\n",
    "# print(trainset[878][0].shape)\n",
    "# print(trainset[878][1])\n",
    "# print(trainset[4203][0].shape)\n",
    "# print(trainset[4203][1])\n",
    "\n",
    "\n",
    "# print(trainset[4289][0].shape)\n",
    "# print(trainset[4289][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, log_interval=100):\n",
    "    model.train()  # set training mode\n",
    "    iteration = 0\n",
    "    for ep in range(epoch):\n",
    "        for batch_idx, (data, target) in enumerate(trainset_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if iteration % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    ep, batch_idx * len(data), len(trainset_loader.dataset),\n",
    "                    100. * batch_idx / len(trainset_loader), loss.item()))\n",
    "            iteration += 1\n",
    "        test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()  # set evaluation mode\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in testset_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(testset_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(testset_loader.dataset),\n",
    "        100. * correct / len(testset_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/4294 (0%)]\tLoss: 0.573998\n",
      "Train Epoch: 0 [100/4294 (2%)]\tLoss: 0.620547\n",
      "Train Epoch: 0 [200/4294 (5%)]\tLoss: 0.837610\n",
      "Train Epoch: 0 [300/4294 (7%)]\tLoss: 0.645405\n",
      "Train Epoch: 0 [400/4294 (9%)]\tLoss: 0.629780\n",
      "Train Epoch: 0 [500/4294 (12%)]\tLoss: 0.606100\n",
      "Train Epoch: 0 [600/4294 (14%)]\tLoss: 0.611902\n",
      "Train Epoch: 0 [700/4294 (16%)]\tLoss: 0.658753\n",
      "Train Epoch: 0 [800/4294 (19%)]\tLoss: 0.760477\n",
      "Train Epoch: 0 [900/4294 (21%)]\tLoss: 0.755285\n",
      "Train Epoch: 0 [1000/4294 (23%)]\tLoss: 0.634080\n",
      "Train Epoch: 0 [1100/4294 (26%)]\tLoss: 0.834025\n",
      "Train Epoch: 0 [1200/4294 (28%)]\tLoss: 0.710429\n",
      "Train Epoch: 0 [1300/4294 (30%)]\tLoss: 0.555280\n",
      "Train Epoch: 0 [1400/4294 (33%)]\tLoss: 0.584127\n",
      "Train Epoch: 0 [1500/4294 (35%)]\tLoss: 0.628395\n",
      "Train Epoch: 0 [1600/4294 (37%)]\tLoss: 0.595649\n",
      "Train Epoch: 0 [1700/4294 (40%)]\tLoss: 0.633261\n",
      "Train Epoch: 0 [1800/4294 (42%)]\tLoss: 0.680240\n",
      "Train Epoch: 0 [1900/4294 (44%)]\tLoss: 0.643093\n",
      "Train Epoch: 0 [2000/4294 (47%)]\tLoss: 0.645482\n",
      "Train Epoch: 0 [2100/4294 (49%)]\tLoss: 0.631669\n",
      "Train Epoch: 0 [2200/4294 (51%)]\tLoss: 0.749868\n",
      "Train Epoch: 0 [2300/4294 (54%)]\tLoss: 0.666191\n",
      "Train Epoch: 0 [2400/4294 (56%)]\tLoss: 0.628948\n",
      "Train Epoch: 0 [2500/4294 (58%)]\tLoss: 0.642839\n",
      "Train Epoch: 0 [2600/4294 (61%)]\tLoss: 0.716032\n",
      "Train Epoch: 0 [2700/4294 (63%)]\tLoss: 0.676677\n",
      "Train Epoch: 0 [2800/4294 (65%)]\tLoss: 0.771435\n",
      "Train Epoch: 0 [2900/4294 (68%)]\tLoss: 0.672974\n",
      "Train Epoch: 0 [3000/4294 (70%)]\tLoss: 0.694797\n",
      "Train Epoch: 0 [3100/4294 (72%)]\tLoss: 0.705326\n",
      "Train Epoch: 0 [3200/4294 (75%)]\tLoss: 0.734961\n",
      "Train Epoch: 0 [3300/4294 (77%)]\tLoss: 0.671679\n",
      "Train Epoch: 0 [3400/4294 (79%)]\tLoss: 0.792422\n",
      "Train Epoch: 0 [3500/4294 (82%)]\tLoss: 0.726442\n",
      "Train Epoch: 0 [3600/4294 (84%)]\tLoss: 0.695766\n",
      "Train Epoch: 0 [3700/4294 (86%)]\tLoss: 0.766179\n",
      "Train Epoch: 0 [3800/4294 (88%)]\tLoss: 0.677200\n",
      "Train Epoch: 0 [3900/4294 (91%)]\tLoss: 0.660622\n",
      "Train Epoch: 0 [4000/4294 (93%)]\tLoss: 0.630562\n",
      "Train Epoch: 0 [4100/4294 (95%)]\tLoss: 0.666684\n",
      "Train Epoch: 0 [4200/4294 (98%)]\tLoss: 0.652830\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid 5347) is killed by signal: Killed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-d7d2359e0623>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# train 5 epochs should get you to about 97% accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-1b855d35606c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, log_interval)\u001b[0m\n\u001b[1;32m     15\u001b[0m                     100. * batch_idx / len(trainset_loader), loss.item()))\n\u001b[1;32m     16\u001b[0m             \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-308844c61378>\u001b[0m in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtestset_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataLoader timed out after {} seconds'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;31m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;31m# Python can still get and update the process status successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0m_error_if_any_worker_fails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprevious_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mprevious_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 5347) is killed by signal: Killed."
     ]
    }
   ],
   "source": [
    "train(1)  # train 5 epochs should get you to about 97% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(checkpoint_path, model, optimizer):\n",
    "    state = {'state_dict': model.state_dict(),\n",
    "             'optimizer' : optimizer.state_dict()}\n",
    "    torch.save(state, checkpoint_path)\n",
    "    print('model saved to %s' % checkpoint_path)\n",
    "    \n",
    "def load_checkpoint(checkpoint_path, model, optimizer):\n",
    "    state = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(state['state_dict'])\n",
    "    optimizer.load_state_dict(state['optimizer'])\n",
    "    print('model loaded from %s' % checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a brand new model\n",
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_save(epoch, save_interval, log_interval=100):\n",
    "    model.train()  # set training mode\n",
    "    iteration = 0\n",
    "    for ep in range(epoch):\n",
    "        for batch_idx, (data, target) in enumerate(trainset_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if iteration % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    ep, batch_idx * len(data), len(trainset_loader.dataset),\n",
    "                    100. * batch_idx / len(trainset_loader), loss.item()))\n",
    "            if iteration % save_interval == 0 and iteration > 0:\n",
    "                save_checkpoint('mnist-%i.pth' % iteration, model, optimizer)\n",
    "            iteration += 1\n",
    "        test()\n",
    "    \n",
    "    # save the final model\n",
    "    save_checkpoint('mnist-%i.pth' % iteration, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_save(5, 500, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new model\n",
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# load from the final checkpoint\n",
    "load_checkpoint('mnist-4690.pth', model, optimizer)\n",
    "# should give you the final model accuracy\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's in a state dict?\n",
    "print(model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('mnist-4690.pth')\n",
    "states_to_load = {}\n",
    "for name, param in checkpoint['state_dict'].items():\n",
    "    if name.startswith('conv'):\n",
    "        states_to_load[name] = param\n",
    "\n",
    "# Construct a new state dict in which the layers we want\n",
    "# to import from the checkpoint is update with the parameters\n",
    "# from the checkpoint\n",
    "model_state = model.state_dict()\n",
    "model_state.update(states_to_load)\n",
    "        \n",
    "model = Net().to(device)\n",
    "model.load_state_dict(model_state)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(1)  # training 1 epoch will get you to 93%!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SmallNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = self.fc1(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = SmallNet().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('mnist-4690.pth')\n",
    "states_to_load = {}\n",
    "for name, param in checkpoint['state_dict'].items():\n",
    "    if name.startswith('conv'):\n",
    "        states_to_load[name] = param\n",
    "\n",
    "# Construct a new state dict in which the layers we want\n",
    "# to import from the checkpoint is update with the parameters\n",
    "# from the checkpoint\n",
    "model_state = model.state_dict()\n",
    "model_state.update(states_to_load)\n",
    "        \n",
    "model.load_state_dict(model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(1)  # training 1 epoch will get you to 93%!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
